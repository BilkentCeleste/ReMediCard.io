{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QCobMmYe-iA"
      },
      "source": [
        "## Install Requirements and Import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJS9-8srbZON",
        "outputId": "63757089-33cf-43fa-ddbd-5fbe61107dd6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/BilkentCeleste/ReMediCard.io.git\n",
        "!mv /content/ReMediCard.io/generation/* /content/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBToZfrHfy67"
      },
      "source": [
        "# Initiliaze Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj9ajeWufyCX"
      },
      "outputs": [],
      "source": [
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE\n",
        "CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE CREDENTIALS HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7RwaT6irPhB"
      },
      "source": [
        "## Load STT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY_Ge80hn57Z"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "from queue_service import RedisQueue\n",
        "from storage_service import S3_Service\n",
        "from generation_service import GenerationService\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n",
        "queue = RedisQueue(queue_name=GENERATION_QUEUE_NAME, host=HOST, db=0, password=PASSWORD)\n",
        "s3Service = S3_Service(AWS_ACCESS_KEY, AWS_SECRET_KEY, REGION)\n",
        "generationService = GenerationService(API_ENDPOINT, API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYxsmfgscw3_",
        "outputId": "2e0fc936-93c4-47e7-c284-0808db1eafb6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "message = queue.wait_message(\n",
        "    queue_name=VOICE_QUEUE_NAME,\n",
        "    host=HOST,\n",
        "    port=PORT,\n",
        "    db=0,\n",
        "    password=PASSWORD\n",
        ")\n",
        "\n",
        "message = json.loads(message[1])\n",
        "S3_URL = message[\"address\"]\n",
        "LANGUAGE = message[\"language\"]\n",
        "\n",
        "s3Service.download_from_s3_url(\n",
        "    s3_url=S3_URL,\n",
        "    local_path=LOCAL_PATH\n",
        ")\n",
        "\n",
        "audio_file = \"/content/downloads/sound.mp3\"\n",
        "\n",
        "language = \"en\" if LANGUAGE == \"ENGLISH\" else \"tr\"\n",
        "\n",
        "result = model.transcribe(audio_file, language=language)  # \"tr\" is for Turkish\n",
        "\n",
        "print(result[\"text\"])\n",
        "\n",
        "prompt = \"Generate an array of flashcards(not specifically should be in basic question forms try to form complex front and back pairs) in the form of an array of json objects for the following text(which is a video transcript for an educative video), don't add any other comment or just I want just an array of json objects with fields front and back so the answer must be like[{\\\"back\\\":\"\",\\\"front\\\":\"\",}], here is the text: \" + result[\"text\"]\n",
        "response = generationService.generate_query(prompt)\n",
        "\n",
        "response_text = response[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "\n",
        "first_squared_bracket = response_text.find(\"[\")\n",
        "last_squared_bracket = response_text.rfind(\"]\") + 1\n",
        "\n",
        "deck = json.loads(response_text[first_squared_bracket:last_squared_bracket])\n",
        "\n",
        "deckTask = {\"flashcards\": deck, \"name\": message[\"fileName\"], \"userId\": message[\"userId\"]}\n",
        "queue.enqueue(deckTask)\n",
        "\n",
        "length = queue.get_queue_length()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
